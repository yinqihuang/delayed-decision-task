{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniGrid_YH",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtIvh94ICiyx"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J5Np0g0Sp4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "8a406714-c163-4beb-aef6-30035eb30270"
      },
      "source": [
        "#@title Setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kglx48HtC3vT"
      },
      "source": [
        "# Create delayed decision task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMieWOxRf0oQ"
      },
      "source": [
        "My goal is to model human memory during a delayed decision task. To mimic the time delay for humans, each episode's delay frame will be an object-less grid. I created the task in array and Matplotlib. The neural network is trained with images generated by Matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfz7LhfXh77j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "d9955af9-d04d-4451-bf7f-0e615dfbaae2"
      },
      "source": [
        "#@title Delayed Decision Task in Array (Not Used)\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# grid room for computer: array\n",
        "# an object with random [shape, size, color]\n",
        "# robj = np.random.randint(0, 3, 3)\n",
        "\n",
        "# create empty room: a 4 by 4 grid with no object\n",
        "# will be used as empty delay frame\n",
        "blank = [[[None, None, None],[None, None, None],[None, None, None],[None, None, None]],\n",
        "         [[None, None, None],[None, None, None],[None, None, None],[None, None, None]],\n",
        "         [[None, None, None],[None, None, None],[None, None, None],[None, None, None]],\n",
        "         [[None, None, None],[None, None, None],[None, None, None],[None, None, None]]]\n",
        "\n",
        "## a random col + a random row in the room\n",
        "# tile = random.choice(random.choice(blank))\n",
        "\n",
        "# cue frame: a room with one random object\n",
        "robj_1 = np.random.randint(0, 3, 3) # object 1 in cue\n",
        "\n",
        "cue_shape = robj_1[0] # cue object's shape\n",
        "\n",
        "row = random.randint(0, 3)\n",
        "col = random.randint(0, 3)\n",
        "blank[row][col] = robj_1\n",
        "cue = blank # cue frame\n",
        "\n",
        "# reset blank\n",
        "blank = [[[None, None, None],[None, None, None],[None, None, None],[None, None, None]],\n",
        "         [[None, None, None],[None, None, None],[None, None, None],[None, None, None]],\n",
        "         [[None, None, None],[None, None, None],[None, None, None],[None, None, None]],\n",
        "         [[None, None, None],[None, None, None],[None, None, None],[None, None, None]]]\n",
        "\n",
        "# test frame: a room with two random objects\n",
        "robj_2 = np.random.randint(0, 3, 3) # object 1 in test\n",
        "robj_2[0] = cue_shape # same shape as cue object\n",
        "row = random.randint(0, 3)\n",
        "col = random.randint(0, 3)\n",
        "blank[row][col] = robj_2\n",
        "\n",
        "robj_3 = np.random.randint(0, 3, 3) # object 2 in test\n",
        "if robj_3[0] != cue_shape: # different shape from cue object\n",
        "    row = random.randint(0, 3)\n",
        "    col = random.randint(0, 3)\n",
        "    blank[row][col] = robj_3\n",
        "    test = blank # test frame\n",
        "\n",
        "# empty delay frame\n",
        "delay = [[[None, None, None],[None, None, None],[None, None, None],[None, None, None]],\n",
        "         [[None, None, None],[None, None, None],[None, None, None],[None, None, None]],\n",
        "         [[None, None, None],[None, None, None],[None, None, None],[None, None, None]],\n",
        "         [[None, None, None],[None, None, None],[None, None, None],[None, None, None]]]\n",
        "\n",
        "# expected CNN output: [shape,shape,shape]\n",
        "\n",
        "print(delay)\n",
        "print(cue)\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[None, None, None], [None, None, None], [None, None, None], [None, None, None]], [[None, None, None], [None, None, None], [None, None, None], [None, None, None]], [[None, None, None], [None, None, None], [None, None, None], [None, None, None]], [[None, None, None], [None, None, None], [None, None, None], [None, None, None]]]\n",
            "[[[None, None, None], [None, None, None], [None, None, None], [None, None, None]], [[None, None, None], [None, None, None], [None, None, None], [None, None, None]], [[None, None, None], [None, None, None], [None, None, None], [None, None, None]], [[None, None, None], array([1, 1, 2]), [None, None, None], [None, None, None]]]\n",
            "[[[None, None, None], [None, None, None], [None, None, None], [None, None, None]], [[None, None, None], [None, None, None], [None, None, None], [None, None, None]], [[None, None, None], array([2, 0, 1]), [None, None, None], [None, None, None]], [[None, None, None], [None, None, None], [None, None, None], [None, None, None]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "imRiFd8XEStf",
        "cellView": "form",
        "outputId": "725ab621-473c-4a71-cc16-905ba91bd115"
      },
      "source": [
        "#@title Delayed Decision Task: Delay Frame in Matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# 4*4 grid = 16 tile\n",
        "tile_1 = plt.Rectangle((1, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_2 = plt.Rectangle((3, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_3 = plt.Rectangle((5, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_4 = plt.Rectangle((7, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_5 = plt.Rectangle((1, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_6 = plt.Rectangle((3, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_7 = plt.Rectangle((5, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_8 = plt.Rectangle((7, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_9 = plt.Rectangle((1, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_10 = plt.Rectangle((3, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_11 = plt.Rectangle((5, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_12 = plt.Rectangle((7, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_13 = plt.Rectangle((1, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_14 = plt.Rectangle((3, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_15 = plt.Rectangle((5, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_16 = plt.Rectangle((7, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "\n",
        "test = plt.gca()\n",
        "test.add_patch(tile_1)\n",
        "test.add_patch(tile_2)\n",
        "test.add_patch(tile_3)\n",
        "test.add_patch(tile_4)\n",
        "test.add_patch(tile_5)\n",
        "test.add_patch(tile_6)\n",
        "test.add_patch(tile_7)\n",
        "test.add_patch(tile_8)\n",
        "test.add_patch(tile_9)\n",
        "test.add_patch(tile_10)\n",
        "test.add_patch(tile_11)\n",
        "test.add_patch(tile_12)\n",
        "test.add_patch(tile_13)\n",
        "test.add_patch(tile_14)\n",
        "test.add_patch(tile_15)\n",
        "test.add_patch(tile_16)\n",
        "\n",
        "plt.axis('scaled')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADn0lEQVR4nO3YQaqrShRA0conc0gG4fxH4iDiKHzNwOW3TIFbWatjy+IcYZMij33fB9Dz39kDAP9PnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqOeMQ9Z1/YwxXjPOOsm2LMvbHhm32uPoy7N+Oa/8Acf4zm+PhrvtcYhrLUSJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFqVpzbpHPOsv15XpU9Wn6a/7Hv+6xBgImeMw5Z1/UzxnjNOOsk27Isb3tk3GqPoy/PutZe+QOO8Z3fHg132+MQfwhBlDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTombFuU065yzbn+dV2aPlp/kf+77PGgSY6DnjkHVdP2OM14yzTrIty/K2R8at9jj68qxr7ZU/4Bjf+e3RcLc9DvGHEESJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFqVpzbpHPOsv15XpU9Wn6a/7Hv+6xBgImeMw5Z1/UzxnjNOOsk27Isb3tk3GqPoy/PutZe+QOO8Z3fHg132+MQfwhBlDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTombFuU065yzbn+dV2aPlp/kf+77PGgSYyLUWosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlToj6B5vXgMOZdC7nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf3bwHTam6ad"
      },
      "source": [
        "Here is to randomize the objects' shape, color, size, and location on the grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Pywd-jBpEMOR",
        "cellView": "form",
        "outputId": "e6eb52f9-59bf-49e1-8d8e-d2a2524a0e1f"
      },
      "source": [
        "#@title Delayed Decision Task: Cue Frame in Matplotlib\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# 4*4 grid = 16 tile\n",
        "tile_1 = plt.Rectangle((1, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_2 = plt.Rectangle((3, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_3 = plt.Rectangle((5, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_4 = plt.Rectangle((7, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_5 = plt.Rectangle((1, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_6 = plt.Rectangle((3, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_7 = plt.Rectangle((5, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_8 = plt.Rectangle((7, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_9 = plt.Rectangle((1, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_10 = plt.Rectangle((3, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_11 = plt.Rectangle((5, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_12 = plt.Rectangle((7, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_13 = plt.Rectangle((1, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_14 = plt.Rectangle((3, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_15 = plt.Rectangle((5, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_16 = plt.Rectangle((7, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "\n",
        "# list of object position\n",
        "square_x = [1.5, 3.5, 5.5, 7.5]\n",
        "square_y = [1.5, 3.5, 5.5, 7.5]\n",
        "triangle_x = [2, 4, 6, 8]\n",
        "triangle_y = [2, 4, 6, 8]\n",
        "circle_x = [2, 4, 6, 8]\n",
        "circle_y = [2, 4, 6, 8]\n",
        "\n",
        "# list of object color\n",
        "colors = ['tomato', 'limegreen', 'lightskyblue']\n",
        "\n",
        "# randomize sqaure's height and weight\n",
        "square_len = random.uniform(0.3, 1)\n",
        "\n",
        "# object with random radius\n",
        "square = plt.Rectangle((random.choice(square_x), random.choice(square_y)), width = square_len,height = square_len, color = random.choice(colors))\n",
        "triangle = mpatches.RegularPolygon((random.choice(triangle_x), random.choice(triangle_y)), 3, radius = random.uniform(0.3, 0.7), color = random.choice(colors))\n",
        "circle = plt.Circle((random.choice(circle_x), random.choice(circle_y)), radius = random.uniform(0.3, 0.7), color = random.choice(colors))\n",
        "\n",
        "cue = plt.gca()\n",
        "cue.add_patch(tile_1)\n",
        "cue.add_patch(tile_2)\n",
        "cue.add_patch(tile_3)\n",
        "cue.add_patch(tile_4)\n",
        "cue.add_patch(tile_5)\n",
        "cue.add_patch(tile_6)\n",
        "cue.add_patch(tile_7)\n",
        "cue.add_patch(tile_8)\n",
        "cue.add_patch(tile_9)\n",
        "cue.add_patch(tile_10)\n",
        "cue.add_patch(tile_11)\n",
        "cue.add_patch(tile_12)\n",
        "cue.add_patch(tile_13)\n",
        "cue.add_patch(tile_14)\n",
        "cue.add_patch(tile_15)\n",
        "cue.add_patch(tile_16)\n",
        "\n",
        "# randomly select one object\n",
        "cue_objects = [square, circle, triangle]\n",
        "cue_object = random.choice(cue_objects)\n",
        "\n",
        "cue.add_patch(cue_object)\n",
        "\n",
        "plt.axis('scaled')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAD2ElEQVR4nO3cMU7cUBRA0T8RyRagT+t1ZNFZh9v0eAsJklMioSiF+eDr0TmNKz/+s3Q11gi47fs+gJ4vZx8A+DdxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROiHmYMWdf1eYzxOGPWSbZlWZ7skXFXexy9edYn55Uf4Biv57dHw73tcYjXWogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRE353dojfv75Pn5/wI//Nl7Gj6+/ps+Fz3baJ+dHhPmRc+Gzea2FKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiDotzm/j5VJz4bOd9n8k/W9Z+D+vtRAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRM2Kc5s05yzbm+tV2aPlXee/7fs+6yDARFP+KmVd1+cxxuOMWSfZlmV5skfGXe1x9OZZr7VXfoBjvJ7fHg33tschvhCCKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRM2Kc5s05yzbm+tV2aPlXee/7fs+6yDARA8zhqzr+jzGeJwx6yTbsixP9si4qz2O3jzrtfbKD3CM1/Pbo+He9jjEF0IQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqFlxbpPmnGV7c70qe7S86/y3fd9nHQSY6GHGkHVdn8cYjzNmnWRbluXJHhl3tcfRm2e91l75AY7xen57NNzbHof4QgiixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQNSvObdKcs2xvrldlj5Z3nf+27/usgwATea2FKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6L+AlmXiu/apaeVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdiMyIaHmkAn"
      },
      "source": [
        "Based on the previous step's randomization, I will randomly take out two objects from the following three options: triangle, square, and circle.I then use a while loop to sort different combinations of the objects, only break the while loop when there is one and only one object's shape match with the cue object.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1A_Ta_sEQO0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "cellView": "form",
        "outputId": "f92ba036-48e6-4ec2-8ae8-1d3bd79177e6"
      },
      "source": [
        "#@title Delayed Decision Task: Test Frame in Matplotlib\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# 4*4 grid = 16 tile\n",
        "tile_1 = plt.Rectangle((1, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_2 = plt.Rectangle((3, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_3 = plt.Rectangle((5, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_4 = plt.Rectangle((7, 1), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_5 = plt.Rectangle((1, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_6 = plt.Rectangle((3, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_7 = plt.Rectangle((5, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_8 = plt.Rectangle((7, 3), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_9 = plt.Rectangle((1, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_10 = plt.Rectangle((3, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_11 = plt.Rectangle((5, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_12 = plt.Rectangle((7, 5), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_13 = plt.Rectangle((1, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_14 = plt.Rectangle((3, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_15 = plt.Rectangle((5, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "tile_16 = plt.Rectangle((7, 7), width=1.9,height=1.9, color = 'lightgrey')\n",
        "\n",
        "# list of object position\n",
        "square_x = [1.5, 3.5, 5.5, 7.5]\n",
        "square_y = [1.5, 3.5, 5.5, 7.5]\n",
        "triangle_x = [2, 4, 6, 8]\n",
        "triangle_y = [2, 4, 6, 8]\n",
        "circle_x = [2, 4, 6, 8]\n",
        "circle_y = [2, 4, 6, 8]\n",
        "\n",
        "# list of object color\n",
        "colors = ['tomato', 'limegreen', 'lightskyblue']\n",
        "\n",
        "# randomize sqaure's height and weight\n",
        "square_len = random.uniform(0.3, 1)\n",
        "\n",
        "# object with random radius\n",
        "square = plt.Rectangle((random.choice(square_x), random.choice(square_y)), width = square_len,height = square_len, color = random.choice(colors))\n",
        "triangle = mpatches.RegularPolygon((random.choice(triangle_x), random.choice(triangle_y)), 3, radius = random.uniform(0.3, 0.7), color = random.choice(colors))\n",
        "circle = plt.Circle((random.choice(circle_x), random.choice(circle_y)), radius = random.uniform(0.3, 0.7), color = random.choice(colors))\n",
        "\n",
        "test = plt.gca()\n",
        "test.add_patch(tile_1)\n",
        "test.add_patch(tile_2)\n",
        "test.add_patch(tile_3)\n",
        "test.add_patch(tile_4)\n",
        "test.add_patch(tile_5)\n",
        "test.add_patch(tile_6)\n",
        "test.add_patch(tile_7)\n",
        "test.add_patch(tile_8)\n",
        "test.add_patch(tile_9)\n",
        "test.add_patch(tile_10)\n",
        "test.add_patch(tile_11)\n",
        "test.add_patch(tile_12)\n",
        "test.add_patch(tile_13)\n",
        "test.add_patch(tile_14)\n",
        "test.add_patch(tile_15)\n",
        "test.add_patch(tile_16)\n",
        "\n",
        "# randomly select two object\n",
        "while True:\n",
        "  square = plt.Rectangle((random.choice(square_x), random.choice(square_y)), width = square_len,height = square_len, color = random.choice(colors))\n",
        "  triangle = mpatches.RegularPolygon((random.choice(triangle_x), random.choice(triangle_y)), 3, radius = random.uniform(0.3, 0.7), color = random.choice(colors))\n",
        "  circle = plt.Circle((random.choice(circle_x), random.choice(circle_y)), radius = random.uniform(0.3, 0.7), color = random.choice(colors))\n",
        "  test_objects = [square, circle, triangle]\n",
        "  t_objects = random.sample(test_objects, 2)\n",
        "  if type(t_objects[0]) == type(cue_object) or type(t_objects[1]) == type(cue_object) and type(t_objects[0]) != type(t_objects[1]): # if one and only one testing object match with cue object\n",
        "    for index, obj in enumerate(t_objects):\n",
        "      test.add_patch(t_objects[index])\n",
        "    break\n",
        "\n",
        "plt.axis('scaled')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3_ftPEwQVPV"
      },
      "source": [
        "I will create a sequence of cue-delay-test using matplotlib.animation and random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8PuJ4H2l9OW"
      },
      "source": [
        "from matplotlib.animation import FuncAnimation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll4Wdfrpw8KH",
        "outputId": "4ac092fa-c969-451d-c514-90bfef9cdbc7"
      },
      "source": [
        "import random # the two random float will be the same\n",
        "\n",
        "random.seed(10) \n",
        "print(random.random())\n",
        "\n",
        "random.seed(10)\n",
        "print(random.random())\n",
        "\n",
        "random.random_integers(1,10) #max length: 10\n",
        "random.random_integers(1,20) #max length: 20\n",
        "random.random_integers(1,30) #max length: 30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5714025946899135\n",
            "0.5714025946899135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvOBwk7ED9hI"
      },
      "source": [
        "# Define neural network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV317ZC_I6gA"
      },
      "source": [
        "Prepare dataset: <br>\n",
        "----\n",
        "1) use only cue frame <br>\n",
        "2) split into train and validation dataset\n",
        "\n",
        "TO DO: <br>\n",
        "1) data bring down to [0, 1] with normalization; <br>\n",
        "2) compare RGB with grayscale.\n",
        "\n",
        "\n",
        "Model architecture: <br>\n",
        "----\n",
        "Input layer: dimensions 256, 256, 3 <br>\n",
        "Output layer: dimensions 1 (flatten to connect with LSTM) <br>\n",
        "\n",
        "Apply 3 Convolutional layer with increasing order of filter size = (8, 16, 32) and fixed kernel size = (2, 2, 2) <br>\n",
        "Apply 3 Max Pooling layers after the convolutional layer\n",
        "\n",
        "Next Step: <br>\n",
        "----\n",
        "1) understand timesteps in LSTM, connect CNN output with LSTM <br>\n",
        "2) get location of the selected object from test frame <br>\n",
        "3) use the center of the object to determine the grid position <br>\n",
        "if 0 < center_x < 2 -> 1st row <br>\n",
        "if 0 < center_y < 2 -> 1st col <br>\n",
        "highlight grid (1,1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JXWCrAhHVsz",
        "cellView": "form",
        "outputId": "d404bb1e-5f89-4ba3-c63f-01ad90168de8"
      },
      "source": [
        "#@title Prepare Training and Validation Images\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory='/content/drive/My Drive/MiniGrid/Train',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=4,\n",
        "    class_names = ['triangle', 'square', 'circle'],\n",
        "    image_size=(256, 256),\n",
        "    shuffle=False,\n",
        "    seed=None,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")\n",
        "\n",
        "validation_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory='/content/drive/My Drive/MiniGrid/Train',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=4,\n",
        "    class_names = ['triangle', 'square', 'circle'],\n",
        "    image_size=(256, 256),\n",
        "    shuffle=False,\n",
        "    seed=None,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 300 files belonging to 3 classes.\n",
            "Using 240 files for training.\n",
            "Found 300 files belonging to 3 classes.\n",
            "Using 60 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ab_Jz6iVWHn"
      },
      "source": [
        "CNN output [circle, square, triangle] <br>\n",
        "if triangle [1, 0, 0] <br>\n",
        "if square [0, 1, 0] <br>\n",
        "if circle [0, 0, 1] <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "t8_jBM1qR9Re",
        "outputId": "aa4d8929-eb2f-4add-db95-b2cfaed1efae"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Input(batch_shape=(4, 256, 256,3)))\n",
        "model.add(keras.layers.Conv2D(filters = 8, kernel_size= 2, strides=(1, 1), data_format = 'channels_last', activation='relu')) #input: 3 RGB channels\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "model.add(keras.layers.Conv2D(filters = 16, kernel_size = 2, strides=(1, 1), activation='relu')) \n",
        "model.add(keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "model.add(keras.layers.Conv2D(filters = 32, kernel_size = 2, strides=(1, 1), activation='relu')) \n",
        "model.add(keras.layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "model.add(keras.layers.Flatten(data_format = 'channels_last')) # connect CNN output with LSTM\n",
        "model.add(keras.layers.LSTM(units = 4, return_sequences=True, return_state=True))\n",
        "model.add(keras.layers.Flatten(data_format = 'channels_last'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-dbf801365a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# connect CNN output with LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1090\u001b[0m       \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer lstm_16 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [4, 2000000]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC5m89WJJDOY"
      },
      "source": [
        "model.fit(train_data, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZyj81ufIcch"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njvyFB_DwwKU",
        "cellView": "form"
      },
      "source": [
        "#@title Convert Array Range to 0 - 1 (Not Used)\n",
        "import numpy as np\n",
        "\n",
        "def NormalizeData(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "\n",
        "norm_data = NormalizeData()\n",
        "print(norm_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc2R0FgnSV23",
        "cellView": "form"
      },
      "source": [
        "#@title Prepare Training Images (Greyscale / 1D) (Not Used)\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "directory = '/content/drive/My Drive/MiniGrid/Train'\n",
        "\n",
        "grey_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=32,\n",
        "    class_names = ['triangle', 'square', 'circle'],\n",
        "    image_size=(256, 256),\n",
        "    shuffle=False,\n",
        "    seed=None,\n",
        "    validation_split=0.5,\n",
        "    subset='training',\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")\n",
        "\n",
        "print(grey_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fymj69PvOs5p"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}